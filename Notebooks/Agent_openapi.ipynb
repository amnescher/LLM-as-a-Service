{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os to set API key\n",
    "import os\n",
    "# Import OpenAI as main LLM service\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# Bring in streamlit for UI/app interface\n",
    "# Import PDF document loaders...there's other ones as well!\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "# Import chroma as the vector store \n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import dotenv_values\n",
    "env_variables = dotenv_values('env.env')\n",
    "os.environ['OPENAI_API_KEY'] = env_variables['Open_API']\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=env_variables['Open_API'],\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "hf_model = \"Salesforce/blip-image-captioning-large\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(hf_model)\n",
    "model = BlipForConditionalGeneration.from_pretrained(hf_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from math import pi\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class CircumferenceTool(BaseTool):\n",
    "    name = \"Circumference calculator\"\n",
    "    description = \"use this tool when you need to calculate a circumference using the radius of a circle\"\n",
    "\n",
    "    def _run(self, radius: Union[int, float]):\n",
    "        return float(radius)*2.0*pi\n",
    "    \n",
    "    def _arun(self, radius: Union[int, float]):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "hf_model = \"Salesforce/blip-image-captioning-large\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(hf_model)\n",
    "model = BlipForConditionalGeneration.from_pretrained(hf_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "\n",
    "desc = (\n",
    "    \"use this tool when given the URL of an image that you'd like to be \"\n",
    "    \"described. It will return a simple caption describing the image.\"\n",
    ")\n",
    "\n",
    "class ImageCaptionTool(BaseTool):\n",
    "    name = \"Image captioner\"\n",
    "    description = desc\n",
    "\n",
    "    def _run(self, url: str):\n",
    "        # download the image and convert to PIL object\n",
    "        image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
    "        # preprocess the image\n",
    "        inputs = processor(image, return_tensors=\"pt\").to(device)\n",
    "        # generate the caption\n",
    "        out = model.generate(**inputs, max_new_tokens=20)\n",
    "        # get the caption\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "        caption = \" I know the answer, inside the image \" + caption\n",
    "        return caption\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "from langchain.agents import load_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vid_url = 'https://www.youtube.com/watch?v=i3OYlaoj-BM'\n",
    "vectorstore = Chroma(\"YouTube_store\", embeddings, persist_directory=\"./YouTube_db\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def add_video_to_DB(url):\n",
    "    loader = YoutubeLoader.from_youtube_url(url, add_video_info=True)\n",
    "    result = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "    texts = text_splitter.split_documents(result)\n",
    "    text =[texts[0]]\n",
    "    vectorstore.add_documents(text)\n",
    "    vectorstore.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "desc = (\n",
    "    \"use this tool when given the URL of a youtube video and that you need you need to watch video to answer questions about video\"\n",
    ")\n",
    "url_list = []\n",
    "class YouTubeRetrival(BaseTool):\n",
    "    name = \"watch video\"\n",
    "    description = desc\n",
    "\n",
    "    def _run(self, url: str):\n",
    "        if url not in url_list:\n",
    "            url_list.append(url)\n",
    "            add_video_to_DB(url)\n",
    "            return \"video saved into vectort database. Now use Retrieval Question Answering tool to answer question. Input to Retrieval Question Answering tool is the question you received about the video \"\n",
    "        else:\n",
    "            return \"video already existed in the database. Now use Retrieval Question Answering tool to answer question. Input to Retrieval Question Answering tool is the question you received about the video \"        \n",
    "              \n",
    "        \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "\n",
    "image_cap = ImageCaptionTool()\n",
    "calcu = CircumferenceTool()\n",
    "QA = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
    "watch_video  =YouTubeRetrival()\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=image_cap.run,\n",
    "        name=\"caption\",\n",
    "        description=\"use this tool only when given the URL of an image that you'd like to be described. It will return a simple string describing the image. once you recived the string don't use any tool and use it as final answer\"\n",
    "        \n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=calcu.run,\n",
    "        name=\"calculator\",\n",
    "        description=\"use this tool only when you need to calculate a circumference using the radius of a circle. it receives a floating point number \"\n",
    "        \n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=watch_video.run,\n",
    "        name=\"Watch Youtube video tool\",\n",
    "        description= \"use this tool Only when given the URL of a youtube video and that you need you need to watch video to answer questions about video\"\n",
    "        \n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=QA.run,\n",
    "        name=\"Retrieval Question Answering tool\",\n",
    "        description= \"Use this tool only after Watch Youtube video tool. It is designed to answer questions about the video using the URL provided.\"\n",
    "        \n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentOutputParser\n",
    "from langchain.agents.conversational_chat.prompt import FORMAT_INSTRUCTIONS\n",
    "from langchain.output_parsers.json import parse_json_markdown\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\n",
    "class OutputParser(AgentOutputParser):\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return FORMAT_INSTRUCTIONS\n",
    "\n",
    "    def parse(self, text: str) -> AgentAction | AgentFinish|str:\n",
    "        \n",
    "        try:\n",
    "            # this will work IF the text is a valid JSON with action and action_input\n",
    "            response = parse_json_markdown(text)\n",
    "            print(response)\n",
    "            action, action_input, Thought= response[\"action\"], response[\"action_input\"],response[\"Thought\"]\n",
    "            if action == \"Final Answer\":\n",
    "                # this means the agent is finished so we call AgentFinish\n",
    "                return AgentFinish({\"output\": action_input}, text)\n",
    "            else:\n",
    "                # otherwise the agent wants to use an action, so we call AgentAction\n",
    "                return AgentAction(action, action_input, text)\n",
    "        except Exception:\n",
    "            # sometimes the agent will return a string that is not a valid JSON\n",
    "            # often this happens when the agent is finished\n",
    "            # so we just return the text as the output\n",
    "            return \"AI:\"\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"conversational_chat\"\n",
    "parser = OutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "from langchain.agents import AgentType\n",
    "llm=OpenAI(temperature=0)\n",
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Hi Bob, nice to meet you! How can I help you?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi, i am bob',\n",
       " 'chat_history': '',\n",
       " 'output': 'Hi Bob, nice to meet you! How can I help you?'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain(\"hi, i am bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Your name is Bob. Is there anything else I can help you with?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what was my name?',\n",
       " 'chat_history': 'Human: hi, i am bob\\nAI: Hi Bob, nice to meet you! How can I help you?',\n",
       " 'output': 'Your name is Bob. Is there anything else I can help you with?'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain(\"what was my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: caption\n",
      "Action Input: https://images.unsplash.com/photo-1568605117036-5fe5e7bab0b7?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1740&q=80\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m I know the answer, inside the image arafed white sports car driving down a winding road at sunset\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The image shows a white sports car driving down a winding road at sunset.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the image in the following link show?\\nhttps://images.unsplash.com/photo-1568605117036-5fe5e7bab0b7?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1740&q=80',\n",
       " 'chat_history': 'Human: hi, i am bob\\nAI: Hi Bob, nice to meet you! How can I help you?\\nHuman: what was my name?\\nAI: Your name is Bob. Is there anything else I can help you with?',\n",
       " 'output': 'The image shows a white sports car driving down a winding road at sunset.'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_url = \"https://images.unsplash.com/photo-1568605117036-5fe5e7bab0b7?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1740&q=80\"\n",
    "agent_chain(f\"What does the image in the following link show?\\n{img_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the circumference of a circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: calculator\n",
      "Action Input: 7.81\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m49.071677249072565\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The circumference of a circle with a radius of 7.81 is 49.071677249072565.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'can you calculate the circumference of a circle that has a radius of 7.81',\n",
       " 'chat_history': 'Human: hi, i am bob\\nAI: Hi Bob, nice to meet you! How can I help you?\\nHuman: what was my name?\\nAI: Your name is Bob. Is there anything else I can help you with?\\nHuman: What does the image in the following link show?\\nhttps://images.unsplash.com/photo-1568605117036-5fe5e7bab0b7?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1740&q=80\\nAI: The image shows a white sports car driving down a winding road at sunset.',\n",
       " 'output': 'The circumference of a circle with a radius of 7.81 is 49.071677249072565.'}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"can you calculate the circumference of a circle that has a radius of 7.81\"\n",
    "agent_chain(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.071677249072565"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import pi\n",
    "(7.81 * 2) * pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: caption\n",
      "Action Input: https://images.unsplash.com/photo-1502680390469-be75c86b636f?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2370&q=80\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m I know the answer, inside the image surfer riding a wave in the ocean on a clear day\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The image shows a surfer riding a wave in the ocean on a clear day.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'https://images.unsplash.com/photo-1502680390469-be75c86b636f?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2370&q=80',\n",
       " 'chat_history': 'Human: hi, i am bob\\nAI: Hi Bob, nice to meet you! How can I help you?\\nHuman: what was my name?\\nAI: Your name is Bob. Is there anything else I can help you with?\\nHuman: What does the image in the following link show?\\nhttps://images.unsplash.com/photo-1568605117036-5fe5e7bab0b7?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1740&q=80\\nAI: The image shows a white sports car driving down a winding road at sunset.\\nHuman: can you calculate the circumference of a circle that has a radius of 7.81\\nAI: The circumference of a circle with a radius of 7.81 is 49.071677249072565.',\n",
       " 'output': 'The image shows a surfer riding a wave in the ocean on a clear day.'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_url = \"https://images.unsplash.com/photo-1502680390469-be75c86b636f?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2370&q=80\"\n",
    "agent_chain(img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question Answering about a YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_url = 'https://www.youtube.com/watch?v=i3OYlaoj-BM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Watch Youtube video tool\n",
      "Action Input: https://www.youtube.com/watch?v=i3OYlaoj-BM\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mvideo saved into vectort database. Now use Retrieval Question Answering tool to answer question. Input to Retrieval Question Answering tool is the question you received about the video \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? Yes\n",
      "Action: Retrieval Question Answering tool\n",
      "Action Input: When did the Imaginative Laws Scale Visual Recognition Challenge take place?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe Imaginative Laws Scale Visual Recognition Challenge took place from around 2010 to 2017.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The Imaginative Laws Scale Visual Recognition Challenge took place from around 2010 to 2017.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': ' According to following YouTube video, When did the Imaginative Laws Scale Visual Recognition Challenge take place??\\nhttps://www.youtube.com/watch?v=i3OYlaoj-BM',\n",
       " 'chat_history': 'Human: hi, i am bob\\nAI: Hi Bob, nice to meet you! How can I help you?\\nHuman: what was my name?\\nAI: Your name is Bob. Is there anything else I can help you with?\\nHuman: What does the image in the following link show?\\nhttps://images.unsplash.com/photo-1568605117036-5fe5e7bab0b7?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1740&q=80\\nAI: The image shows a white sports car driving down a winding road at sunset.\\nHuman: can you calculate the circumference of a circle that has a radius of 7.81\\nAI: The circumference of a circle with a radius of 7.81 is 49.071677249072565.\\nHuman: https://images.unsplash.com/photo-1502680390469-be75c86b636f?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2370&q=80\\nAI: The image shows a surfer riding a wave in the ocean on a clear day.',\n",
       " 'output': 'The Imaginative Laws Scale Visual Recognition Challenge took place from around 2010 to 2017.'}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain(f\" According to following YouTube video, When did the Imaginative Laws Scale Visual Recognition Challenge take place??\\n{vid_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Watch Youtube video tool\n",
      "Action Input: https://www.youtube.com/watch?v=i3OYlaoj-BM\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mvideo already existed in the database. Now use Retrieval Question Answering tool to answer question. Input to Retrieval Question Answering tool is the question you received about the video \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? Yes\n",
      "Action: Retrieval Question Answering tool\n",
      "Action Input: In the following video, What was the purpose of the competition that acted as the go-to place for finding the current state of the art in image classification, object localization, and object detection?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe purpose of the competition was to serve as a platform for finding the current state of the art in image classification, object localization, and object detection. It acted as a go-to place for researchers and practitioners to showcase their advancements and innovations in these areas.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The competition was a great way for researchers and practitioners to showcase their advancements and innovations in image classification, object localization, and object detection.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': ' In the following video, What was the purpose of the competition that acted as the go-to place for finding the current state of the art in image classification, object localization, and object detection?\\nhttps://www.youtube.com/watch?v=i3OYlaoj-BM',\n",
       " 'chat_history': 'Human: hi, i am bob\\nAI: Hi Bob, nice to meet you! How can I help you?\\nHuman: what was my name?\\nAI: Your name is Bob. Is there anything else I can help you with?\\nHuman: What does the image in the following link show?\\nhttps://images.unsplash.com/photo-1568605117036-5fe5e7bab0b7?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1740&q=80\\nAI: The image shows a white sports car driving down a winding road at sunset.\\nHuman: can you calculate the circumference of a circle that has a radius of 7.81\\nAI: The circumference of a circle with a radius of 7.81 is 49.071677249072565.\\nHuman: https://images.unsplash.com/photo-1502680390469-be75c86b636f?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2370&q=80\\nAI: The image shows a surfer riding a wave in the ocean on a clear day.\\nHuman:  According to following YouTube video, When did the Imaginative Laws Scale Visual Recognition Challenge take place??\\nhttps://www.youtube.com/watch?v=i3OYlaoj-BM\\nAI: The Imaginative Laws Scale Visual Recognition Challenge took place from around 2010 to 2017.',\n",
       " 'output': 'The competition was a great way for researchers and practitioners to showcase their advancements and innovations in image classification, object localization, and object detection.'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent_chain(f\" In the following video, What was the purpose of the competition that acted as the go-to place for finding the current state of the art in image classification, object localization, and object detection?\\n{vid_url}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
