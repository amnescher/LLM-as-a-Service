version: '3.4'
services:
  frontend:
    build:
      context: ./frontend
    image: frontend
    ports:
      - "8501:8501"
    depends_on:
      - backend
    environment:
      - ENV_VARIABLE=some_value
  backend:
    build:
      context: ./backend
    environment:
      - Hugging_ACCESS_TOKEN
    image: llama2-backend
    ports:
      - "5000:5000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: always