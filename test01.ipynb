{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdaf82b-e14d-4fde-9576-6f23692a8cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6d0b077a-1b59-4179-8482-6b2b26128c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import func_to_container_op\n",
    "from typing import NamedTuple\n",
    "\n",
    "def download_data_from_minio(ip_address: str, port: int, access_key: str, secret_key: str, bucket_name: str, object_name: str):\n",
    "\n",
    "    import sys\n",
    "    import tarfile\n",
    "    from minio import Minio\n",
    "    import os\n",
    "\n",
    "\n",
    "    client = Minio(\n",
    "        f\"{ip_address}:{port}\",\n",
    "        access_key=access_key,\n",
    "        secret_key=secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    found = client.bucket_exists(bucket_name)\n",
    "    if found:\n",
    "        print(\"Found the bucket\")\n",
    "        #Download data from MinIO bucket\n",
    "        client.fget_object(\n",
    "            bucket_name,\n",
    "            object_name,\n",
    "            object_name\n",
    "        )\n",
    "        print(f\"Downloaded {object_name} from {bucket_name} bucket\")\n",
    "        # create a TarFile object for the specified file\n",
    "        tar = tarfile.open(object_name)\n",
    "\n",
    "        # extract all files in the tar file to the current working directory\n",
    "        tar.extractall(\"/mnt/\")\n",
    "        directory_path = '/mnt/'\n",
    "\n",
    "        # Use os.listdir() to get a list of all files and directories in the directory\n",
    "        contents = os.listdir(directory_path)\n",
    "        for root, dirs, files in os.walk(directory_path):\n",
    "            for file in files:\n",
    "                print(os.path.join(root, file))\n",
    "\n",
    "        # Print the list of contents\n",
    "        print(contents)\n",
    "\n",
    "        # close the TarFile object\n",
    "        tar.close()\n",
    "    else:\n",
    "        print(f\"{bucket_name} bucket does not exist.\")\n",
    "        sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "97bf0f9a-332b-45ad-8ca5-88423b080172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the bucket\n",
      "Downloaded VOCtrainval_11-May-2012.tar from voc2012-bucket bucket\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/mnt/VOCdevkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdownload_data_from_minio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m185.47.227.233\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m9000\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEschercloud_CV_demo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murF2FbUWv85dYtjB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoc2012-bucket\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVOCtrainval_11-May-2012.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[165], line 33\u001b[0m, in \u001b[0;36mdownload_data_from_minio\u001b[0;34m(ip_address, port, access_key, secret_key, bucket_name, object_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m tar \u001b[38;5;241m=\u001b[39m tarfile\u001b[38;5;241m.\u001b[39mopen(object_name)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# extract all files in the tar file to the current working directory\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Use os.listdir() to get a list of all files and directories in the directory\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/tarfile.py:2028\u001b[0m, in \u001b[0;36mTarFile.extractall\u001b[0;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[1;32m   2026\u001b[0m         tarinfo\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0o700\u001b[39m\n\u001b[1;32m   2027\u001b[0m     \u001b[38;5;66;03m# Do not set_attrs directories, as we will do that further down\u001b[39;00m\n\u001b[0;32m-> 2028\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;66;03m# Reverse sort directories.\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m directories\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/tarfile.py:2069\u001b[0m, in \u001b[0;36mTarFile.extract\u001b[0;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2066\u001b[0m     tarinfo\u001b[38;5;241m.\u001b[39m_link_target \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, tarinfo\u001b[38;5;241m.\u001b[39mlinkname)\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2069\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrorlevel \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/tarfile.py:2143\u001b[0m, in \u001b[0;36mTarFile._extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakefile(tarinfo, targetpath)\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[0;32m-> 2143\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misfifo():\n\u001b[1;32m   2145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakefifo(tarinfo, targetpath)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/tarfile.py:2172\u001b[0m, in \u001b[0;36mTarFile.makedir\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make a directory called targetpath.\u001b[39;00m\n\u001b[1;32m   2168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2170\u001b[0m     \u001b[38;5;66;03m# Use a safe mode for the directory, the real mode is set\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m     \u001b[38;5;66;03m# later in _extract_member().\u001b[39;00m\n\u001b[0;32m-> 2172\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0o700\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/mnt/VOCdevkit'"
     ]
    }
   ],
   "source": [
    "#download_data_from_minio(\"185.47.227.233\", '9000',\"Eschercloud_CV_demo\",\"urF2FbUWv85dYtjB\", \"voc2012-bucket\", \"VOCtrainval_11-May-2012.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f65877a6-0ea9-4569-9007-ab0d23b8f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_voc_dataset(path: str) -> List[str]:\n",
    "    from pathlib import Path\n",
    "    import torchvision.transforms as T\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from PIL import Image\n",
    "    import os\n",
    "    # Define augmentations\n",
    "    transforms_list = [\n",
    "        T.Compose([\n",
    "            T.Resize((224, 224), interpolation=Image.NEAREST),\n",
    "\n",
    "        ]),\n",
    "        T.Compose([\n",
    "           # T.RandomHorizontalFlip(p=1.0),\n",
    "           # T.RandomRotation(degrees=(-180, 180)),\n",
    "            T.Resize((224, 224), interpolation=Image.NEAREST),\n",
    "\n",
    "        ])\n",
    "    ]\n",
    "    directory_path = '/mnt/'\n",
    "\n",
    "    # Use os.listdir() to get a list of all files and directories in the directory\n",
    "    contents = os.listdir(directory_path)\n",
    "\n",
    "    # Print the list of contents\n",
    "    print(contents)\n",
    "    # Create preprocessed dataset directories\n",
    "    versions = ['version1', 'version2']\n",
    "    version_paths = [Path(path) / v for v in versions]\n",
    "    for version_path in version_paths:\n",
    "        (version_path / 'JPEGImages').mkdir(parents=True, exist_ok=True)\n",
    "        (version_path / 'SegmentationClass').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define dataset loader\n",
    "    class VOC2012PreprocessedDataset(Dataset):\n",
    "        def __init__(self, path: str, transform):\n",
    "            self.path = path\n",
    "            self.transform = transform\n",
    "            \n",
    "            self.imgs_path = sorted(list(Path(path).glob('JPEGImages/*.jpg')))\n",
    "            self.masks_path = sorted(list(Path(path).glob('SegmentationClass/*.png')))\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.imgs_path)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            img_path = self.imgs_path[idx]\n",
    "            mask_path = self.masks_path[idx]\n",
    "            \n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            mask = Image.open(mask_path).convert('P')\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "                mask = self.transform(mask)\n",
    "            \n",
    "            # Resize mask using nearest neighbor interpolation to preserve segmentation classes\n",
    "            \n",
    "            \n",
    "            \n",
    "            return img, mask\n",
    "    transforms_list= [None,None]\n",
    "    # Preprocess datasets\n",
    "    directory_path = '/mnt/'\n",
    "\n",
    "    # Use os.listdir() to get a list of all files and directories in the directory\n",
    "    contents = os.listdir(directory_path)\n",
    "\n",
    "    # Print the list of contents\n",
    "    print(contents)\n",
    "    for i, transform in enumerate(transforms_list):\n",
    "        \n",
    "        dataset = VOC2012PreprocessedDataset(path, transform)\n",
    "        version_path = version_paths[i]\n",
    "        for j in range(len(dataset)):\n",
    "            print('-------->',j)\n",
    "            img, mask = dataset[j]\n",
    "            img_path = version_path / 'JPEGImages' / (f'{j:06}.jpg')\n",
    "            mask_path = version_path / 'SegmentationClass' / (f'{j:06}.png')\n",
    "            img.save(img_path)\n",
    "            mask.save(mask_path)\n",
    "            \n",
    "    return [str(v) for v in version_paths]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "278c6274-8c56-4759-b047-1a247a9c9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import NamedTuple\n",
    "def load_voc2012_segmentation_dataset(root_dir: str) -> NamedTuple('Outputs', [('train_loader', DataLoader), ('val_loader', DataLoader)]):\n",
    "    from PIL import Image\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torchvision.transforms import ToTensor\n",
    "    import os\n",
    "\n",
    "    class VOC2012SegmentationDataset(Dataset):\n",
    "        def __init__(self, root_dir, split='train', transform=None, resize_shape=(375, 500)):\n",
    "            self.root_dir = root_dir\n",
    "            self.split = split\n",
    "            self.transform = transform\n",
    "            self.resize_shape = resize_shape\n",
    "            self.to_tensor = ToTensor()\n",
    "\n",
    "            # read list of image IDs\n",
    "            directory_path = '/mnt/'\n",
    "\n",
    "            # Use os.listdir() to get a list of all files and directories in the directory\n",
    "            contents = os.listdir(directory_path)\n",
    "\n",
    "            # Print the list of contents\n",
    "            print(contents)\n",
    "            with open(os.path.join(root_dir, 'ImageSets', 'Segmentation', f'{split}.txt'), 'r') as f:\n",
    "                self.image_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_ids)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            # load image and label\n",
    "            image_path = os.path.join(self.root_dir, 'JPEGImages', f'{self.image_ids[idx]}.jpg')\n",
    "            label_path = os.path.join(self.root_dir, 'SegmentationClass', f'{self.image_ids[idx]}.png')\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            label = Image.open(label_path).convert('L')\n",
    "\n",
    "            # resize image and label\n",
    "            image = image.resize(self.resize_shape)\n",
    "            label = label.resize(self.resize_shape)\n",
    "\n",
    "            # apply transform if specified\n",
    "            if self.transform is not None:\n",
    "                image, label = self.transform(image, label)\n",
    "\n",
    "            # convert to PyTorch tensor\n",
    "            image = self.to_tensor(image)\n",
    "            label = self.to_tensor(label)\n",
    "\n",
    "            return image, label\n",
    "\n",
    "    train_dataset = VOC2012SegmentationDataset(root_dir=root_dir, split='train')\n",
    "    val_dataset = VOC2012SegmentationDataset(root_dir=root_dir, split='val')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    return (train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3f234143-cf1b-4606-a9f4-c099eecf7aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f7d858558b0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f7d7d91d760>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_voc2012_segmentation_dataset('VOCdevkit/VOC2012/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0103a12d-7174-4e05-8692-76d322adb174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_volume():\n",
    "    import os\n",
    "    with open(\"/mnt/file.txt\", \"w\") as file:\n",
    "        file.write(\"Hello world\")\n",
    "    for root, dirs, files in os.walk(\"/mnt/\"):\n",
    "            for file in files:\n",
    "                print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "23307fac-9874-43b1-a1e7-b124b6bf6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file_op():\n",
    "    with open('/mnt/file.txt', 'w') as f:\n",
    "        f.write('Hello world!')\n",
    "        \n",
    "def read_file_op():\n",
    "    with open('/mnt/file.txt', 'r') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0ced2da8-4969-4183-80bc-46c35ee8a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/4ef26038-bb3f-42a1-8aa9-9d8eb651483d\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/61ca31a5-8e3f-4e15-a6c7-d687ca62c786\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp.components import create_component_from_func\n",
    "from kfp import dsl\n",
    "from typing import List\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "# Define the components\n",
    "#download_data_from_minio_op = create_component_from_func(download_data_from_minio, base_image='python:3.8', packages_to_install=['minio'])\n",
    "#preprocess_voc_dataset_op = create_component_from_func(preprocess_voc_dataset, base_image='pytorch/pytorch:1.9.0-cuda10.2-cudnn7-runtime', packages_to_install=['torchvision', 'pillow'])\n",
    "#data_loader_op = create_component_from_func(load_voc2012_segmentation_dataset,output_component_file='load_voc2012_segmentation_dataset.yaml',base_image='pytorch/pytorch:1.10.0-cuda11.3-cudnn8-runtime')\n",
    "write_to_volume_op = create_component_from_func(write_to_volume, base_image='python:3.8')\n",
    "read_from_volume_op = create_component_from_func(read_file_op, base_image='python:3.8')\n",
    "@dsl.pipeline(\n",
    "    name='VOC2012 Preprocessing Pipeline test',\n",
    "    description='A pipeline that preprocesses VOC2012 dataset'\n",
    ")\n",
    "def voc2012_preprocessing_pipeline_test(\n",
    "    ip_address: str,\n",
    "    port: int,\n",
    "    access_key: str,\n",
    "    secret_key: str,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    local_path: str,\n",
    "    root_dir: str\n",
    ") -> List[str]:\n",
    "    \n",
    "    vop = dsl.VolumeOp(\n",
    "        name=\"shared-volume\",\n",
    "        resource_name=\"shared-volume\",\n",
    "        modes=[\"ReadWriteMany\"],\n",
    "        size=\"1Gi\"\n",
    "    )\n",
    "    \n",
    "    # Define the pipeline\n",
    "    download_task = download_data_from_minio_op(ip_address, port, access_key, secret_key, bucket_name, object_name).set_display_name('Download Data from Minio').add_pvolumes({\"/mnt\": vop.volume})\n",
    "    #preprocess_task = preprocess_voc_dataset_op(root_dir).after(download_task).set_display_name('Preprocess VOC2012 Dataset').add_pvolumes({\"/mnt'\": download_task.pvolume})\n",
    "    print_task = write_to_volume_op().after(download_task).set_display_name('printing data in mnt directory').add_pvolumes({\"/mnt\": vop.volume})\n",
    "    #dataloader_task = data_loader_op(root_dir).after(download_task).set_display_name('Preparing data').add_pvolumes({\"/mnt'\": vop.volume})\n",
    "        # Set cache option to CACHE_NONE\n",
    "    #write_task = write_to_volume_op().set_display_name('write file').add_pvolumes({\"/mnt\": vop.volume})\n",
    "    #read_task = read_from_volume_op().after(write_task).set_display_name('read file').add_pvolumes({\"/mnt\": vop.volume})\n",
    "    return None\n",
    "\n",
    "# Compile the pipeline\n",
    "pipeline_func = voc2012_preprocessing_pipeline_test\n",
    "pipeline_filename = pipeline_func.__name__ + '.yaml'\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename)\n",
    "\n",
    "# Connect to the Kubeflow Pipeline and submit the pipeline for execution\n",
    "client = kfp.Client()\n",
    "experiment_name = 'Downloading data Pipeline'\n",
    "experiment = client.create_experiment(experiment_name)\n",
    "run_name = 'run'\n",
    "\n",
    "arguments = {\n",
    "    'ip_address': \"185.47.227.233\",\n",
    "    'port': '9000',\n",
    "    'access_key': \"Eschercloud_CV_demo\",\n",
    "    'secret_key': \"urF2FbUWv85dYtjB\",\n",
    "    'bucket_name': \"voc2012-bucket\",\n",
    "    'object_name': \"VOCtrainval_11-May-2012.tar\",\n",
    "    'local_path': \"dataset/VOCtrainval_11-May-2012.tar\",\n",
    "    'root_dir': '/mnt/'\n",
    "}\n",
    "\n",
    "run = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9ba3be9d-8f06-47cf-9cdb-a972ad26cca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164eff9c-c2f3-4f89-afd1-1eb3bf49e720\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "\n",
    "# Connect to the Kubeflow Pipeline client\n",
    "client = kfp.Client()\n",
    "\n",
    "# Get a list of all experiments\n",
    "experiments = client.list_experiments()\n",
    "# Delete all runs in each experiment\n",
    "if experiments.experiments:\n",
    "    for experiment in experiments.experiments:\n",
    "            print(experiment.id)\n",
    "            client.delete_experiment(experiment.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4e3128d0-5607-4455-9adb-47de2b212367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95400384-d67d-421d-9187-4034ec69dcac\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import kfp\n",
    "\n",
    "# Connect to the Kubeflow Pipeline client\n",
    "client = kfp.Client()\n",
    "# Get a list of all experiments\n",
    "runs = client.list_runs()\n",
    "# Delete all runs in each experiment\n",
    "if runs.runs:\n",
    "    for run in runs.runs:\n",
    "        print(run.id)\n",
    "        kfp.Client().runs.delete_run(run.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900d51a-5804-4cd9-8939-7bb24c5a3f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0942ca6f-2549-427c-b756-32b09f63c0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/00bb0d96-d7f1-441b-9897-264d77479a62\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/b567e4ee-fa34-4729-a0f9-1f698ed3724f\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "@dsl.pipeline(name='Shared Volume Pipeline', description='A pipeline with two components sharing a volume')\n",
    "def my_pipeline():\n",
    "    # Define the shared volume\n",
    "    vop = dsl.VolumeOp(\n",
    "        name=\"shared-volume\",\n",
    "        resource_name=\"shared-volume\",\n",
    "        modes=[\"ReadWriteMany\"],\n",
    "        size=\"1Gi\"\n",
    "    )\n",
    "\n",
    "    # First component to write the text file\n",
    "    write_file = dsl.ContainerOp(\n",
    "        name='write-file',\n",
    "        image='ubuntu',\n",
    "        command=['sh', '-c'],\n",
    "        arguments=['echo \"Hello World!\" > /mnt/test.txt'],\n",
    "        pvolumes={\"/mnt\": vop.volume}\n",
    "    )\n",
    "\n",
    "    # Second component to read and print the text file\n",
    "    read_file = dsl.ContainerOp(\n",
    "        name='read-file',\n",
    "        image='ubuntu',\n",
    "        command=['sh', '-c'],\n",
    "        arguments=['cat /mnt/test.txt'],\n",
    "        pvolumes={\"/mnt\": vop.volume}\n",
    "    )\n",
    "\n",
    "    # Print the output of the second component\n",
    "    read_file.after(write_file)\n",
    "    read_file.container.set_image_pull_policy(\"Always\")\n",
    "    read_file.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kfp.compiler.Compiler().compile(my_pipeline, 'my_pipeline.yaml')\n",
    "    client = kfp.Client()\n",
    "    experiment = client.create_experiment('my_experiment')\n",
    "    run = client.run_pipeline(experiment.id, 'my_run', 'my_pipeline.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8bd539c2-56cd-4fd3-b8dc-61d6a486fcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"voc2012-preprocessing-pipeline-test-swzhp-3021110133\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete pod voc2012-preprocessing-pipeline-test-swzhp-3021110133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56826d-6ba9-4b80-9518-0ebcb5f06ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e321f3-c620-4e85-9700-fcb42e2fcc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "class VOC2012SegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None, resize_shape=(375, 500)):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.resize_shape = resize_shape\n",
    "        self.to_tensor = ToTensor()\n",
    "\n",
    "        # read list of image IDs\n",
    "        with open(os.path.join(root_dir, 'ImageSets', 'Segmentation', f'{split}.txt'), 'r') as f:\n",
    "            self.image_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load image and label\n",
    "        image_path = os.path.join(self.root_dir, 'JPEGImages', f'{self.image_ids[idx]}.jpg')\n",
    "        label_path = os.path.join(self.root_dir, 'SegmentationClass', f'{self.image_ids[idx]}.png')\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = Image.open(label_path).convert('L')\n",
    "\n",
    "        # resize image and label\n",
    "        image = image.resize(self.resize_shape)\n",
    "        label = label.resize(self.resize_shape)\n",
    "\n",
    "        # apply transform if specified\n",
    "        if self.transform is not None:\n",
    "            image, label = self.transform(image, label)\n",
    "\n",
    "        # convert to PyTorch tensor\n",
    "        image = self.to_tensor(image)\n",
    "        label = self.to_tensor(label)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a0bae6-a30b-4971-9c38-74c92cda968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eecc331d-5bf5-4764-a3e9-9a279154a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import create_component_from_func\n",
    "from kfp import dsl\n",
    "from typing import NamedTuple\n",
    "\n",
    "# Define download_data_from_minio component\n",
    "download_data_from_minio_op = create_component_from_func(download_data_from_minio,\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['minio']\n",
    ")\n",
    "\n",
    "# Define load_voc2012_segmentation_dataset component\n",
    "load_voc2012_segmentation_dataset_op = create_component_from_func(load_voc2012_segmentation_dataset,\n",
    "    base_image='pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime',\n",
    "    packages_to_install=['torchvision', 'pillow']\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "@dsl.pipeline(name='VOC2012 Segmentation Dataset Pipeline', description='An example Kubeflow pipeline')\n",
    "def voc2012_segmentation_dataset_pipeline(ip_address: str, port: int, access_key: str, secret_key: str, bucket_name: str, object_name: str, local_path: str, root_dir: str):\n",
    "    # Define download_data_from_minio task\n",
    "    download_data_from_minio_task = download_data_from_minio_op(ip_address, port, access_key, secret_key, bucket_name, object_name, local_path)\n",
    "\n",
    "    # Define load_voc2012_segmentation_dataset task\n",
    "    load_voc2012_segmentation_dataset_task = load_voc2012_segmentation_dataset_op(root_dir)\n",
    "\n",
    "    # Set upstream dependency of load_voc2012_segmentation_dataset_task on download_data_from_minio_task\n",
    "    load_voc2012_segmentation_dataset_task.after(download_data_from_minio_task)\n",
    "    \n",
    "    # Print the output of load_voc2012_segmentation_dataset_task\n",
    "    print_op = dsl.ContainerOp(\n",
    "        name='print',\n",
    "        image='alpine',\n",
    "        command=['echo', str(load_voc2012_segmentation_dataset_task.outputs)]\n",
    "    )\n",
    "\n",
    "# Compile pipeline\n",
    "pipeline_func = voc2012_segmentation_dataset_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.yaml'\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beeff30-501b-4b7e-96d5-1bae28f10667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import create_component_from_func\n",
    "\n",
    "# Define pipeline input arguments\n",
    "@dsl.pipeline(\n",
    "    name='VOC2012 Segmentation Pipeline',\n",
    "    description='A pipeline to download VOC2012 segmentation dataset and load it'\n",
    ")\n",
    "def voc2012_pipeline(\n",
    "    ip_address: str,\n",
    "    port: int,\n",
    "    access_key: str,\n",
    "    secret_key: str,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    local_path: str,\n",
    "    root_dir: str\n",
    "):\n",
    "    # Define download_data_from_minio component\n",
    "    download_op = create_component_from_func(download_data_from_minio, base_image='python:3.9',packages_to_install=['minio'])(\n",
    "        ip_address,\n",
    "        port,\n",
    "        access_key,\n",
    "        secret_key,\n",
    "        bucket_name,\n",
    "        object_name,\n",
    "        local_path\n",
    "    )\n",
    "\n",
    "    # Define load_voc2012_segmentation_dataset component\n",
    "    load_op = create_component_from_func(load_voc2012_segmentation_dataset, base_image='pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime', packages_to_install=['torchvision', 'pillow'] )(\n",
    "        root_dir\n",
    "    )\n",
    "\n",
    "    # Connect the components\n",
    "    load_op(download_op.outputs['local_path'])\n",
    "\n",
    "# Define the pipeline's argument values\n",
    "arguments = {\n",
    "    'ip_address': \"185.47.227.233\",\n",
    "    'port': '9000',\n",
    "    'access_key': \"Eschercloud_CV_demo\",\n",
    "    'secret_key': \"urF2FbUWv85dYtjB\",\n",
    "    'bucket_name': \"voc2012-bucket\",\n",
    "    'object_name': \"VOCtrainval_11-May-2012.tar\",\n",
    "    'local_path': \"dataset/VOCtrainval_11-May-2012.tar\",\n",
    "    'root_dir': 'VOCdevkit/VOC2012/'\n",
    "}\n",
    "\n",
    "\"voc2012-bucket\",\"VOCtrainval_11-May-2012.tar\",\"dataset/VOCtrainval_11-May-2012.tar\"\n",
    "\n",
    "# Compile and run the pipeline\n",
    "kfp.compiler.Compiler().compile(voc2012_pipeline, 'voc2012_pipeline.zip')\n",
    "client = kfp.Client()\n",
    "run = client.create_run_from_pipeline_func(voc2012_pipeline, arguments=arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e7162e-3be0-42b4-bec6-94f4beb84aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05272b0b-da57-4f4c-9689-cce72177fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a1861-4e1b-47bf-a3e4-0deab414be54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabe496-5a76-4e4c-b6a8-fda91318d4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1464 (0%)]\tLoss: 2.952618\n",
      "Train Epoch: 1 [20/1464 (1%)]\tLoss: 1.886380\n",
      "Train Epoch: 1 [40/1464 (3%)]\tLoss: 1.464575\n",
      "Train Epoch: 1 [60/1464 (4%)]\tLoss: 1.042962\n",
      "Train Epoch: 1 [80/1464 (5%)]\tLoss: 0.780367\n",
      "Train Epoch: 1 [100/1464 (7%)]\tLoss: 0.536833\n",
      "Train Epoch: 1 [120/1464 (8%)]\tLoss: 0.359450\n",
      "Train Epoch: 1 [140/1464 (10%)]\tLoss: 0.263180\n",
      "Train Epoch: 1 [160/1464 (11%)]\tLoss: 0.184007\n",
      "Train Epoch: 1 [180/1464 (12%)]\tLoss: 0.128336\n",
      "Train Epoch: 1 [200/1464 (14%)]\tLoss: 0.100734\n",
      "Train Epoch: 1 [220/1464 (15%)]\tLoss: 0.085040\n",
      "Train Epoch: 1 [240/1464 (16%)]\tLoss: 0.070334\n",
      "Train Epoch: 1 [260/1464 (18%)]\tLoss: 0.058812\n",
      "Train Epoch: 1 [280/1464 (19%)]\tLoss: 0.051609\n",
      "Train Epoch: 1 [300/1464 (20%)]\tLoss: 0.046397\n",
      "Train Epoch: 1 [320/1464 (22%)]\tLoss: 0.041160\n",
      "Train Epoch: 1 [340/1464 (23%)]\tLoss: 0.037058\n",
      "Train Epoch: 1 [360/1464 (25%)]\tLoss: 0.032303\n",
      "Train Epoch: 1 [380/1464 (26%)]\tLoss: 0.029153\n",
      "Train Epoch: 1 [400/1464 (27%)]\tLoss: 0.026468\n",
      "Train Epoch: 1 [420/1464 (29%)]\tLoss: 0.024212\n",
      "Train Epoch: 1 [440/1464 (30%)]\tLoss: 0.022540\n",
      "Train Epoch: 1 [460/1464 (31%)]\tLoss: 0.020154\n",
      "Train Epoch: 1 [480/1464 (33%)]\tLoss: 0.019004\n",
      "Train Epoch: 1 [500/1464 (34%)]\tLoss: 0.017788\n",
      "Train Epoch: 1 [520/1464 (36%)]\tLoss: 0.017351\n",
      "Train Epoch: 1 [540/1464 (37%)]\tLoss: 0.015138\n",
      "Train Epoch: 1 [560/1464 (38%)]\tLoss: 0.014405\n",
      "Train Epoch: 1 [580/1464 (40%)]\tLoss: 0.014049\n",
      "Train Epoch: 1 [600/1464 (41%)]\tLoss: 0.012485\n",
      "Train Epoch: 1 [620/1464 (42%)]\tLoss: 0.011697\n",
      "Train Epoch: 1 [640/1464 (44%)]\tLoss: 0.012398\n",
      "Train Epoch: 1 [660/1464 (45%)]\tLoss: 0.010632\n",
      "Train Epoch: 1 [680/1464 (46%)]\tLoss: 0.010291\n",
      "Train Epoch: 1 [700/1464 (48%)]\tLoss: 0.009780\n",
      "Train Epoch: 1 [720/1464 (49%)]\tLoss: 0.009047\n",
      "Train Epoch: 1 [740/1464 (51%)]\tLoss: 0.008663\n",
      "Train Epoch: 1 [760/1464 (52%)]\tLoss: 0.008131\n",
      "Train Epoch: 1 [780/1464 (53%)]\tLoss: 0.007924\n",
      "Train Epoch: 1 [800/1464 (55%)]\tLoss: 0.007435\n",
      "Train Epoch: 1 [820/1464 (56%)]\tLoss: 0.007179\n",
      "Train Epoch: 1 [840/1464 (57%)]\tLoss: 0.006838\n",
      "Train Epoch: 1 [860/1464 (59%)]\tLoss: 0.006662\n",
      "Train Epoch: 1 [880/1464 (60%)]\tLoss: 0.006257\n",
      "Train Epoch: 1 [900/1464 (61%)]\tLoss: 0.006252\n",
      "Train Epoch: 1 [920/1464 (63%)]\tLoss: 0.005812\n",
      "Train Epoch: 1 [940/1464 (64%)]\tLoss: 0.005654\n",
      "Train Epoch: 1 [960/1464 (66%)]\tLoss: 0.005404\n",
      "Train Epoch: 1 [980/1464 (67%)]\tLoss: 0.005224\n",
      "Train Epoch: 1 [1000/1464 (68%)]\tLoss: 0.005022\n",
      "Train Epoch: 1 [1020/1464 (70%)]\tLoss: 0.004840\n",
      "Train Epoch: 1 [1040/1464 (71%)]\tLoss: 0.004689\n",
      "Train Epoch: 1 [1060/1464 (72%)]\tLoss: 0.004586\n",
      "Train Epoch: 1 [1080/1464 (74%)]\tLoss: 0.004395\n",
      "Train Epoch: 1 [1100/1464 (75%)]\tLoss: 0.004140\n",
      "Train Epoch: 1 [1120/1464 (77%)]\tLoss: 0.004053\n",
      "Train Epoch: 1 [1140/1464 (78%)]\tLoss: 0.004212\n",
      "Train Epoch: 1 [1160/1464 (79%)]\tLoss: 0.003860\n",
      "Train Epoch: 1 [1180/1464 (81%)]\tLoss: 0.003711\n",
      "Train Epoch: 1 [1200/1464 (82%)]\tLoss: 0.003572\n",
      "Train Epoch: 1 [1220/1464 (83%)]\tLoss: 0.003495\n",
      "Train Epoch: 1 [1240/1464 (85%)]\tLoss: 0.003414\n",
      "Train Epoch: 1 [1260/1464 (86%)]\tLoss: 0.003330\n",
      "Train Epoch: 1 [1280/1464 (87%)]\tLoss: 0.003223\n",
      "Train Epoch: 1 [1300/1464 (89%)]\tLoss: 0.003164\n",
      "Train Epoch: 1 [1320/1464 (90%)]\tLoss: 0.003063\n",
      "Train Epoch: 1 [1340/1464 (92%)]\tLoss: 0.002953\n",
      "Train Epoch: 1 [1360/1464 (93%)]\tLoss: 0.002925\n",
      "Train Epoch: 1 [1380/1464 (94%)]\tLoss: 0.002851\n",
      "Train Epoch: 1 [1400/1464 (96%)]\tLoss: 0.002690\n",
      "Train Epoch: 1 [1420/1464 (97%)]\tLoss: 0.002643\n",
      "Train Epoch: 1 [1440/1464 (98%)]\tLoss: 0.002625\n",
      "Train Epoch: 1 [1460/1464 (100%)]\tLoss: 0.002550\n",
      "Train Epoch: 2 [0/1464 (0%)]\tLoss: 0.002497\n",
      "Train Epoch: 2 [20/1464 (1%)]\tLoss: 0.002468\n",
      "Train Epoch: 2 [40/1464 (3%)]\tLoss: 0.002429\n",
      "Train Epoch: 2 [60/1464 (4%)]\tLoss: 0.002372\n",
      "Train Epoch: 2 [80/1464 (5%)]\tLoss: 0.002252\n",
      "Train Epoch: 2 [100/1464 (7%)]\tLoss: 0.002211\n",
      "Train Epoch: 2 [120/1464 (8%)]\tLoss: 0.002157\n",
      "Train Epoch: 2 [140/1464 (10%)]\tLoss: 0.002164\n",
      "Train Epoch: 2 [160/1464 (11%)]\tLoss: 0.002060\n",
      "Train Epoch: 2 [180/1464 (12%)]\tLoss: 0.002042\n",
      "Train Epoch: 2 [200/1464 (14%)]\tLoss: 0.001988\n",
      "Train Epoch: 2 [220/1464 (15%)]\tLoss: 0.001955\n",
      "Train Epoch: 2 [240/1464 (16%)]\tLoss: 0.001888\n",
      "Train Epoch: 2 [260/1464 (18%)]\tLoss: 0.001882\n",
      "Train Epoch: 2 [280/1464 (19%)]\tLoss: 0.001832\n",
      "Train Epoch: 2 [300/1464 (20%)]\tLoss: 0.001801\n",
      "Train Epoch: 2 [320/1464 (22%)]\tLoss: 0.001765\n",
      "Train Epoch: 2 [340/1464 (23%)]\tLoss: 0.001758\n",
      "Train Epoch: 2 [360/1464 (25%)]\tLoss: 0.001694\n",
      "Train Epoch: 2 [380/1464 (26%)]\tLoss: 0.001652\n",
      "Train Epoch: 2 [400/1464 (27%)]\tLoss: 0.001584\n",
      "Train Epoch: 2 [420/1464 (29%)]\tLoss: 0.001596\n",
      "Train Epoch: 2 [440/1464 (30%)]\tLoss: 0.001535\n",
      "Train Epoch: 2 [460/1464 (31%)]\tLoss: 0.001495\n",
      "Train Epoch: 2 [480/1464 (33%)]\tLoss: 0.001500\n",
      "Train Epoch: 2 [500/1464 (34%)]\tLoss: 0.001438\n",
      "Train Epoch: 2 [520/1464 (36%)]\tLoss: 0.001437\n",
      "Train Epoch: 2 [540/1464 (37%)]\tLoss: 0.001418\n",
      "Train Epoch: 2 [560/1464 (38%)]\tLoss: 0.001415\n",
      "Train Epoch: 2 [580/1464 (40%)]\tLoss: 0.001378\n",
      "Train Epoch: 2 [600/1464 (41%)]\tLoss: 0.001353\n",
      "Train Epoch: 2 [620/1464 (42%)]\tLoss: 0.001344\n",
      "Train Epoch: 2 [640/1464 (44%)]\tLoss: 0.001301\n",
      "Train Epoch: 2 [660/1464 (45%)]\tLoss: 0.001262\n",
      "Train Epoch: 2 [680/1464 (46%)]\tLoss: 0.001263\n",
      "Train Epoch: 2 [700/1464 (48%)]\tLoss: 0.001226\n",
      "Train Epoch: 2 [720/1464 (49%)]\tLoss: 0.001233\n",
      "Train Epoch: 2 [740/1464 (51%)]\tLoss: 0.001172\n",
      "Train Epoch: 2 [760/1464 (52%)]\tLoss: 0.001154\n",
      "Train Epoch: 2 [780/1464 (53%)]\tLoss: 0.001161\n",
      "Train Epoch: 2 [800/1464 (55%)]\tLoss: 0.001098\n",
      "Train Epoch: 2 [820/1464 (56%)]\tLoss: 0.001119\n",
      "Train Epoch: 2 [840/1464 (57%)]\tLoss: 0.001093\n",
      "Train Epoch: 2 [860/1464 (59%)]\tLoss: 0.001065\n",
      "Train Epoch: 2 [880/1464 (60%)]\tLoss: 0.001039\n",
      "Train Epoch: 2 [900/1464 (61%)]\tLoss: 0.001038\n",
      "Train Epoch: 2 [920/1464 (63%)]\tLoss: 0.001013\n",
      "Train Epoch: 2 [940/1464 (64%)]\tLoss: 0.001014\n",
      "Train Epoch: 2 [960/1464 (66%)]\tLoss: 0.001014\n",
      "Train Epoch: 2 [980/1464 (67%)]\tLoss: 0.000956\n",
      "Train Epoch: 2 [1000/1464 (68%)]\tLoss: 0.000955\n",
      "Train Epoch: 2 [1020/1464 (70%)]\tLoss: 0.000934\n",
      "Train Epoch: 2 [1040/1464 (71%)]\tLoss: 0.000915\n",
      "Train Epoch: 2 [1060/1464 (72%)]\tLoss: 0.000913\n",
      "Train Epoch: 2 [1080/1464 (74%)]\tLoss: 0.000912\n",
      "Train Epoch: 2 [1100/1464 (75%)]\tLoss: 0.000886\n",
      "Train Epoch: 2 [1120/1464 (77%)]\tLoss: 0.000872\n",
      "Train Epoch: 2 [1140/1464 (78%)]\tLoss: 0.000851\n",
      "Train Epoch: 2 [1160/1464 (79%)]\tLoss: 0.000868\n",
      "Train Epoch: 2 [1180/1464 (81%)]\tLoss: 0.000828\n",
      "Train Epoch: 2 [1200/1464 (82%)]\tLoss: 0.000825\n",
      "Train Epoch: 2 [1220/1464 (83%)]\tLoss: 0.000812\n",
      "Train Epoch: 2 [1240/1464 (85%)]\tLoss: 0.000779\n",
      "Train Epoch: 2 [1260/1464 (86%)]\tLoss: 0.000779\n",
      "Train Epoch: 2 [1280/1464 (87%)]\tLoss: 0.000785\n",
      "Train Epoch: 2 [1300/1464 (89%)]\tLoss: 0.000763\n",
      "Train Epoch: 2 [1320/1464 (90%)]\tLoss: 0.000737\n",
      "Train Epoch: 2 [1340/1464 (92%)]\tLoss: 0.000746\n",
      "Train Epoch: 2 [1360/1464 (93%)]\tLoss: 0.000720\n",
      "Train Epoch: 2 [1380/1464 (94%)]\tLoss: 0.000720\n",
      "Train Epoch: 2 [1400/1464 (96%)]\tLoss: 0.000713\n",
      "Train Epoch: 2 [1420/1464 (97%)]\tLoss: 0.000709\n",
      "Train Epoch: 2 [1440/1464 (98%)]\tLoss: 0.000685\n",
      "Train Epoch: 2 [1460/1464 (100%)]\tLoss: 0.000682\n",
      "Train Epoch: 3 [0/1464 (0%)]\tLoss: 0.000681\n",
      "Train Epoch: 3 [20/1464 (1%)]\tLoss: 0.000670\n",
      "Train Epoch: 3 [40/1464 (3%)]\tLoss: 0.000699\n",
      "Train Epoch: 3 [60/1464 (4%)]\tLoss: 0.000680\n",
      "Train Epoch: 3 [80/1464 (5%)]\tLoss: 0.000680\n",
      "Train Epoch: 3 [100/1464 (7%)]\tLoss: 0.000638\n",
      "Train Epoch: 3 [120/1464 (8%)]\tLoss: 0.000634\n",
      "Train Epoch: 3 [140/1464 (10%)]\tLoss: 0.000620\n",
      "Train Epoch: 3 [160/1464 (11%)]\tLoss: 0.000602\n",
      "Train Epoch: 3 [180/1464 (12%)]\tLoss: 0.000596\n",
      "Train Epoch: 3 [200/1464 (14%)]\tLoss: 0.000592\n",
      "Train Epoch: 3 [220/1464 (15%)]\tLoss: 0.000588\n",
      "Train Epoch: 3 [240/1464 (16%)]\tLoss: 0.000582\n",
      "Train Epoch: 3 [260/1464 (18%)]\tLoss: 0.000581\n",
      "Train Epoch: 3 [280/1464 (19%)]\tLoss: 0.000570\n",
      "Train Epoch: 3 [300/1464 (20%)]\tLoss: 0.000564\n",
      "Train Epoch: 3 [320/1464 (22%)]\tLoss: 0.000557\n",
      "Train Epoch: 3 [340/1464 (23%)]\tLoss: 0.000539\n",
      "Train Epoch: 3 [360/1464 (25%)]\tLoss: 0.000536\n",
      "Train Epoch: 3 [380/1464 (26%)]\tLoss: 0.000533\n",
      "Train Epoch: 3 [400/1464 (27%)]\tLoss: 0.000531\n",
      "Train Epoch: 3 [420/1464 (29%)]\tLoss: 0.000526\n",
      "Train Epoch: 3 [440/1464 (30%)]\tLoss: 0.000512\n",
      "Train Epoch: 3 [460/1464 (31%)]\tLoss: 0.000497\n",
      "Train Epoch: 3 [480/1464 (33%)]\tLoss: 0.000497\n",
      "Train Epoch: 3 [500/1464 (34%)]\tLoss: 0.000496\n",
      "Train Epoch: 3 [520/1464 (36%)]\tLoss: 0.000498\n",
      "Train Epoch: 3 [540/1464 (37%)]\tLoss: 0.000484\n",
      "Train Epoch: 3 [560/1464 (38%)]\tLoss: 0.000489\n",
      "Train Epoch: 3 [580/1464 (40%)]\tLoss: 0.000472\n",
      "Train Epoch: 3 [600/1464 (41%)]\tLoss: 0.000465\n",
      "Train Epoch: 3 [620/1464 (42%)]\tLoss: 0.000459\n",
      "Train Epoch: 3 [640/1464 (44%)]\tLoss: 0.000455\n",
      "Train Epoch: 3 [660/1464 (45%)]\tLoss: 0.000454\n",
      "Train Epoch: 3 [680/1464 (46%)]\tLoss: 0.000443\n",
      "Train Epoch: 3 [700/1464 (48%)]\tLoss: 0.000442\n",
      "Train Epoch: 3 [720/1464 (49%)]\tLoss: 0.000438\n",
      "Train Epoch: 3 [740/1464 (51%)]\tLoss: 0.000437\n",
      "Train Epoch: 3 [760/1464 (52%)]\tLoss: 0.000436\n",
      "Train Epoch: 3 [780/1464 (53%)]\tLoss: 0.000416\n",
      "Train Epoch: 3 [800/1464 (55%)]\tLoss: 0.000414\n",
      "Train Epoch: 3 [820/1464 (56%)]\tLoss: 0.000422\n",
      "Train Epoch: 3 [840/1464 (57%)]\tLoss: 0.000412\n",
      "Train Epoch: 3 [860/1464 (59%)]\tLoss: 0.000401\n",
      "Train Epoch: 3 [880/1464 (60%)]\tLoss: 0.000394\n",
      "Train Epoch: 3 [900/1464 (61%)]\tLoss: 0.000395\n",
      "Train Epoch: 3 [920/1464 (63%)]\tLoss: 0.000399\n",
      "Train Epoch: 3 [940/1464 (64%)]\tLoss: 0.000392\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munet_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 55\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# train and test loop\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m---> 55\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#         test(model, device, val_loader)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munet_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(output, target\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     25\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minc(x)\n\u001b[0;32m---> 26\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(x2)\n\u001b[1;32m     28\u001b[0m     x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown3(x3)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mDown.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpool_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:399\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:395\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    393\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    394\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = nn.CrossEntropyLoss()(output, target.squeeze(dim=1).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.CrossEntropyLoss()(output, target.squeeze(dim=1).long()).item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def main():\n",
    "    # set up device (GPU if available)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    " \n",
    "\n",
    "    # set up data loaders\n",
    "    train_dataset = VOC2012SegmentationDataset(root_dir='VOCdevkit/VOC2012/', split='train')\n",
    "    val_dataset = VOC2012SegmentationDataset(root_dir='VOCdevkit/VOC2012/', split='val')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # set up model and optimizer\n",
    "    model = UNet(n_channels=3, n_classes=21).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # train and test loop\n",
    "    for epoch in range(1, 11):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "#         test(model, device, val_loader)\n",
    "\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), \"unet_model.pt\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b3133-5ebf-4ab3-afdb-3c9504a6d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component\n",
    "def prepare_data_op(data_path: str, train_val_split_ratio: float) -> NamedTuple('Outputs', [('train_data', str), ('val_data', str)]):\n",
    "    import torch.utils.data as data\n",
    "    from torchvision import transforms\n",
    "    from data_loader import VOC2012SegmentationDataset\n",
    "    \n",
    "    # Define the data transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "408c87ee-a2ae-46c3-b518-2f67aefadabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/2beea759-a401-41e0-bc8d-eccea9768e12\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/c1a1ce26-b3e8-486e-92c5-5a679072d699\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import func_to_container_op\n",
    "from kfp.components import InputPath, OutputPath\n",
    "\n",
    "# Define the component for our training function\n",
    "@func_to_container_op\n",
    "def train_op(data_path: InputPath(str), model_path: OutputPath(str)):\n",
    "\n",
    "    from PIL import Image\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset\n",
    "    from torchvision.transforms import ToTensor\n",
    "    import os\n",
    "    class VOC2012SegmentationDataset(Dataset):\n",
    "        def __init__(self, root_dir, split='train', transform=None, resize_shape=(375, 500)):\n",
    "            self.root_dir = root_dir\n",
    "            self.split = split\n",
    "            self.transform = transform\n",
    "            self.resize_shape = resize_shape\n",
    "            self.to_tensor = ToTensor()\n",
    "\n",
    "            # read list of image IDs\n",
    "            with open(os.path.join(root_dir, 'ImageSets', 'Segmentation', f'{split}.txt'), 'r') as f:\n",
    "                self.image_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_ids)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            # load image and label\n",
    "            image_path = os.path.join(self.root_dir, 'JPEGImages', f'{self.image_ids[idx]}.jpg')\n",
    "            label_path = os.path.join(self.root_dir, 'SegmentationClass', f'{self.image_ids[idx]}.png')\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            label = Image.open(label_path).convert('L')\n",
    "\n",
    "            # resize image and label\n",
    "            image = image.resize(self.resize_shape)\n",
    "            label = label.resize(self.resize_shape)\n",
    "\n",
    "            # apply transform if specified\n",
    "            if self.transform is not None:\n",
    "                image, label = self.transform(image, label)\n",
    "\n",
    "            # convert to PyTorch tensor\n",
    "            image = self.to_tensor(image)\n",
    "            label = self.to_tensor(label)\n",
    "\n",
    "            return image, label\n",
    "    \n",
    "    \"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "\n",
    "    class DoubleConv(nn.Module):\n",
    "        \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "        def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "            super().__init__()\n",
    "            if not mid_channels:\n",
    "                mid_channels = out_channels\n",
    "            self.double_conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(mid_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.double_conv(x)\n",
    "\n",
    "\n",
    "    class Down(nn.Module):\n",
    "        \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.maxpool_conv = nn.Sequential(\n",
    "                nn.MaxPool2d(2),\n",
    "                DoubleConv(in_channels, out_channels)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "    class Up(nn.Module):\n",
    "        \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "        def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "            super().__init__()\n",
    "\n",
    "            # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "            if bilinear:\n",
    "                self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "                self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "            else:\n",
    "                self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "                self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "        def forward(self, x1, x2):\n",
    "            x1 = self.up(x1)\n",
    "            # input is CHW\n",
    "            diffY = x2.size()[2] - x1.size()[2]\n",
    "            diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "            x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "            # if you have padding issues, see\n",
    "            # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "            # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "            x = torch.cat([x2, x1], dim=1)\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "    class OutConv(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super(OutConv, self).__init__()\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "    \"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    class UNet(nn.Module):\n",
    "        def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "            super(UNet, self).__init__()\n",
    "            self.n_channels = n_channels\n",
    "            self.n_classes = n_classes\n",
    "            self.bilinear = bilinear\n",
    "\n",
    "            self.inc = (DoubleConv(n_channels, 64))\n",
    "            self.down1 = (Down(64, 128))\n",
    "            self.down2 = (Down(128, 256))\n",
    "            self.down3 = (Down(256, 512))\n",
    "            factor = 2 if bilinear else 1\n",
    "            self.down4 = (Down(512, 1024 // factor))\n",
    "            self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "            self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "            self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "            self.up4 = (Up(128, 64, bilinear))\n",
    "            self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x1 = self.inc(x)\n",
    "            x2 = self.down1(x1)\n",
    "            x3 = self.down2(x2)\n",
    "            x4 = self.down3(x3)\n",
    "            x5 = self.down4(x4)\n",
    "            x = self.up1(x5, x4)\n",
    "            x = self.up2(x, x3)\n",
    "            x = self.up3(x, x2)\n",
    "            x = self.up4(x, x1)\n",
    "            logits = self.outc(x)\n",
    "            return logits\n",
    "\n",
    "        def use_checkpointing(self):\n",
    "            self.inc = torch.utils.checkpoint(self.inc)\n",
    "            self.down1 = torch.utils.checkpoint(self.down1)\n",
    "            self.down2 = torch.utils.checkpoint(self.down2)\n",
    "            self.down3 = torch.utils.checkpoint(self.down3)\n",
    "            self.down4 = torch.utils.checkpoint(self.down4)\n",
    "            self.up1 = torch.utils.checkpoint(self.up1)\n",
    "            self.up2 = torch.utils.checkpoint(self.up2)\n",
    "            self.up3 = torch.utils.checkpoint(self.up3)\n",
    "            self.up4 = torch.utils.checkpoint(self.up4)\n",
    "            self.outc = torch.utils.checkpoint(self.outc)\n",
    "\n",
    "    def train(model, device, train_loader, optimizer, epoch):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = nn.CrossEntropyLoss()(output, target.squeeze(dim=1).long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader\n",
    "        # set up device (GPU if available)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "        # set up data loaders\n",
    "    train_dataset = VOC2012SegmentationDataset(root_dir=data_path, split='train')\n",
    "    val_dataset = VOC2012SegmentationDataset(root_dir=data_path, split='val')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # set up model and optimizer\n",
    "    model = UNet(n_channels=3, n_classes=21).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # train and test loop\n",
    "    for epoch in range(1, 11):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "    name='UNet Training Pipeline',\n",
    "    description='Pipeline to train UNet for image segmentation'\n",
    ")\n",
    "def unet_training_pipeline(data_path: str, model_path: str):\n",
    "    train = train_op(data_path)\n",
    "\n",
    "# Compile the pipeline\n",
    "pipeline_func = unet_training_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.zip'\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename)\n",
    "\n",
    "# Connect to the Kubeflow Pipeline and submit the pipeline for execution\n",
    "client = kfp.Client()\n",
    "experiment_name = 'UNet Training Pipeline'\n",
    "experiment = client.create_experiment(experiment_name)\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run = client.run_pipeline(experiment.id, run_name, pipeline_filename, params={\n",
    "    'data_path': 'VOCdevkit/VOC2012/',\n",
    "    'model_path': 'models/unet_model.pt'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5cae9-f5ea-4c83-9555-fadb64f51380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
